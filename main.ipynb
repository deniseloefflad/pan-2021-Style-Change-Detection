{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run './style_change_detection.py' \"./mini-set/\" \"./mini-val/\" \"./cc.en.300.vec.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/envs/style-change-detection/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package punkt to /home/robert/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/robert/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import style_change_detection\n",
    "from style_change_detection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------downloaded---------\n",
      "-------read folder -------------\n",
      "-------read validation -------------\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_3 (Masking)          (None, 47, 5)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 47, 256)           137216    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 47, 1)             257       \n",
      "=================================================================\n",
      "Total params: 137,473\n",
      "Trainable params: 137,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "8960/8960 - 129s - loss: 0.0883 - val_loss: 0.0861\n",
      "Epoch 2/1000\n",
      "8960/8960 - 123s - loss: 0.0864 - val_loss: 0.0860\n",
      "Epoch 3/1000\n",
      "8960/8960 - 129s - loss: 0.0863 - val_loss: 0.0860\n",
      "Epoch 4/1000\n",
      "8960/8960 - 129s - loss: 0.0862 - val_loss: 0.0857\n",
      "Epoch 5/1000\n",
      "8960/8960 - 129s - loss: 0.0861 - val_loss: 0.0857\n",
      "Epoch 6/1000\n",
      "8960/8960 - 130s - loss: 0.0861 - val_loss: 0.0858\n",
      "Epoch 7/1000\n",
      "8960/8960 - 129s - loss: 0.0860 - val_loss: 0.0854\n",
      "Epoch 8/1000\n",
      "8960/8960 - 129s - loss: 0.0857 - val_loss: 0.0856\n",
      "Epoch 9/1000\n",
      "8960/8960 - 130s - loss: 0.0856 - val_loss: 0.0856\n",
      "Epoch 10/1000\n",
      "8960/8960 - 129s - loss: 0.0855 - val_loss: 0.0850\n",
      "Epoch 11/1000\n",
      "8960/8960 - 130s - loss: 0.0854 - val_loss: 0.0850\n",
      "Epoch 12/1000\n",
      "8960/8960 - 129s - loss: 0.0854 - val_loss: 0.0851\n",
      "Epoch 13/1000\n",
      "8960/8960 - 132s - loss: 0.0853 - val_loss: 0.0849\n",
      "Epoch 14/1000\n",
      "8960/8960 - 132s - loss: 0.0852 - val_loss: 0.0850\n",
      "Epoch 15/1000\n",
      "8960/8960 - 125s - loss: 0.0851 - val_loss: 0.0848\n",
      "Epoch 16/1000\n",
      "8960/8960 - 129s - loss: 0.0852 - val_loss: 0.0850\n",
      "Epoch 17/1000\n",
      "8960/8960 - 132s - loss: 0.0851 - val_loss: 0.0849\n",
      "Epoch 18/1000\n",
      "8960/8960 - 130s - loss: 0.0851 - val_loss: 0.0847\n",
      "Epoch 19/1000\n",
      "8960/8960 - 132s - loss: 0.0850 - val_loss: 0.0855\n",
      "Epoch 20/1000\n",
      "8960/8960 - 131s - loss: 0.0850 - val_loss: 0.0850\n",
      "Epoch 21/1000\n",
      "8960/8960 - 123s - loss: 0.0850 - val_loss: 0.0846\n",
      "Epoch 22/1000\n",
      "8960/8960 - 131s - loss: 0.0850 - val_loss: 0.0849\n",
      "Epoch 23/1000\n",
      "8960/8960 - 130s - loss: 0.0850 - val_loss: 0.0849\n",
      "Epoch 24/1000\n",
      "8960/8960 - 150s - loss: 0.0849 - val_loss: 0.0846\n",
      "Epoch 25/1000\n",
      "8960/8960 - 130s - loss: 0.0848 - val_loss: 0.0846\n",
      "Epoch 26/1000\n",
      "8960/8960 - 125s - loss: 0.0849 - val_loss: 0.0849\n",
      "Epoch 27/1000\n",
      "8960/8960 - 131s - loss: 0.0848 - val_loss: 0.0848\n",
      "Epoch 28/1000\n",
      "8960/8960 - 128s - loss: 0.0848 - val_loss: 0.0847\n",
      "Epoch 29/1000\n",
      "8960/8960 - 135s - loss: 0.0847 - val_loss: 0.0848\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "batch size 1\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_4 (Masking)          (None, 47, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 47, 256)           439296    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 47, 1)             257       \n",
      "=================================================================\n",
      "Total params: 439,553\n",
      "Trainable params: 439,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "8960/8960 - 305s - loss: 0.0872 - val_loss: 0.0842\n",
      "Epoch 2/1000\n",
      "8960/8960 - 326s - loss: 0.0840 - val_loss: 0.0821\n",
      "Epoch 3/1000\n",
      "8960/8960 - 298s - loss: 0.0810 - val_loss: 0.0796\n",
      "Epoch 4/1000\n",
      "8960/8960 - 279s - loss: 0.0789 - val_loss: 0.0786\n",
      "Epoch 5/1000\n",
      "8960/8960 - 284s - loss: 0.0775 - val_loss: 0.0774\n",
      "Epoch 6/1000\n",
      "8960/8960 - 265s - loss: 0.0763 - val_loss: 0.0771\n",
      "Epoch 7/1000\n",
      "8960/8960 - 243s - loss: 0.0751 - val_loss: 0.0775\n",
      "Epoch 8/1000\n",
      "8960/8960 - 241s - loss: 0.0740 - val_loss: 0.0766\n",
      "Epoch 9/1000\n",
      "8960/8960 - 242s - loss: 0.0727 - val_loss: 0.0755\n",
      "Epoch 10/1000\n",
      "8960/8960 - 241s - loss: 0.0712 - val_loss: 0.0764\n",
      "Epoch 11/1000\n",
      "8960/8960 - 240s - loss: 0.0696 - val_loss: 0.0781\n",
      "Epoch 12/1000\n",
      "8960/8960 - 242s - loss: 0.0681 - val_loss: 0.0780\n",
      "Epoch 13/1000\n",
      "8960/8960 - 242s - loss: 0.0659 - val_loss: 0.0792\n",
      "Epoch 14/1000\n",
      "8960/8960 - 237s - loss: 0.0638 - val_loss: 0.0826\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "batch size 1\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_5 (Masking)          (None, 47, 305)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 47, 256)           444416    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 47, 1)             257       \n",
      "=================================================================\n",
      "Total params: 444,673\n",
      "Trainable params: 444,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "8960/8960 - 238s - loss: 0.0868 - val_loss: 0.0858\n",
      "Epoch 2/1000\n",
      "8960/8960 - 233s - loss: 0.0844 - val_loss: 0.0834\n",
      "Epoch 3/1000\n",
      "8960/8960 - 233s - loss: 0.0816 - val_loss: 0.0806\n",
      "Epoch 4/1000\n",
      "8960/8960 - 233s - loss: 0.0790 - val_loss: 0.0804\n",
      "Epoch 5/1000\n",
      "8960/8960 - 233s - loss: 0.0774 - val_loss: 0.0776\n",
      "Epoch 6/1000\n",
      "8960/8960 - 232s - loss: 0.0762 - val_loss: 0.0775\n",
      "Epoch 7/1000\n",
      "8960/8960 - 233s - loss: 0.0754 - val_loss: 0.0769\n",
      "Epoch 8/1000\n",
      "8960/8960 - 234s - loss: 0.0743 - val_loss: 0.0756\n",
      "Epoch 9/1000\n",
      "8960/8960 - 233s - loss: 0.0733 - val_loss: 0.0760\n",
      "Epoch 10/1000\n",
      "8960/8960 - 232s - loss: 0.0720 - val_loss: 0.0762\n",
      "Epoch 11/1000\n",
      "8960/8960 - 232s - loss: 0.0705 - val_loss: 0.0766\n",
      "Epoch 12/1000\n",
      "8960/8960 - 233s - loss: 0.0691 - val_loss: 0.0778\n",
      "Epoch 13/1000\n",
      "8960/8960 - 233s - loss: 0.0674 - val_loss: 0.0784\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "batch size 1\n",
      "results complexity measures precision, recall, f1, accuracy: [0.8316927027605393, 0.0765548825528143, 0.14020436323626229, 0.09446238601823709]\n",
      "results embeddings precision, recall, f1, accuracy: [0.7514444682216991, 0.07084564868709083, 0.12948366934926298, 0.10304901215805472]\n",
      "results combined precision, recall, f1, accuracy: [0.7685640915899851, 0.07222144020591606, 0.13203558692695122, 0.10298252279635259]\n",
      "majority baseline accuracy: 0.9105148176291793\n",
      "random baseline accuracy: 0.5889912613981763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_2(\"./train/\", \"./validation/\", \"./cc.en.300.vec.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------downloaded---------\n",
      "-------read folder -------------\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = \"./train/\"\n",
    "validation_folder = \"./validation/\"\n",
    "embeddings_dict = \"./cc.en.300.vec.gz\"\n",
    "\n",
    "\n",
    "if embedding_model == None:\n",
    "    embedding_model = gensim.models.KeyedVectors.load_word2vec_format(embeddings_dict, binary=False, limit=200000)\n",
    "\n",
    "print(\"--------downloaded---------\")\n",
    "compl_measures_all, text_ids, labels_all, embedding_all_docs = read_data(dataset_folder, embedding_model)\n",
    "print(\"-------read folder -------------\")\n",
    "val_compl_measures, val_text_ids, val_labels_all, val_embedding_all_docs = read_data(validation_folder, embedding_model)\n",
    "\n",
    "target = 'multi-author'\n",
    "val_labels = [item[target] for item in val_labels_all]\n",
    "train_labels = [item[target] for item in labels_all]  # sc = style change\n",
    "\n",
    "#----------------- complexity measures\n",
    "padded_compl_measures, padded_labels_style_change, padded_val_x, padded_val_y = padding(compl_measures_all,\n",
    "                                                                                        train_labels,\n",
    "                                                                                        val_compl_measures,\n",
    "                                                                                        val_labels, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 47, 5)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 47, 256)           137216    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 47, 1)             257       \n",
      "=================================================================\n",
      "Total params: 137,473\n",
      "Trainable params: 137,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "8960/8960 - 140s - loss: 0.0683 - val_loss: -2.5979e+00\n",
      "Epoch 2/1000\n",
      "8960/8960 - 136s - loss: 0.0672 - val_loss: -1.9706e+00\n",
      "Epoch 3/1000\n",
      "8960/8960 - 136s - loss: 0.0669 - val_loss: -2.4157e+00\n",
      "Epoch 4/1000\n",
      "8960/8960 - 134s - loss: 0.0666 - val_loss: -3.0147e+00\n",
      "Epoch 5/1000\n",
      "8960/8960 - 135s - loss: 0.0667 - val_loss: -2.4968e+00\n",
      "Epoch 6/1000\n",
      "8960/8960 - 133s - loss: 0.0665 - val_loss: -1.8528e+00\n",
      "Epoch 7/1000\n",
      "8960/8960 - 151s - loss: 0.0663 - val_loss: -2.2257e+00\n",
      "Epoch 8/1000\n",
      "8960/8960 - 135s - loss: 0.0663 - val_loss: -2.7513e+00\n",
      "Epoch 9/1000\n",
      "8960/8960 - 136s - loss: 0.0662 - val_loss: -2.8546e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "batch size 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 47, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 47, 256)           439296    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 47, 1)             257       \n",
      "=================================================================\n",
      "Total params: 439,553\n",
      "Trainable params: 439,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "8960/8960 - 259s - loss: 0.0664 - val_loss: 0.0649\n",
      "Epoch 2/1000\n",
      "8960/8960 - 257s - loss: 0.0638 - val_loss: 0.0658\n",
      "Epoch 3/1000\n",
      "8960/8960 - 253s - loss: 0.0625 - val_loss: 0.0650\n",
      "Epoch 4/1000\n",
      "8960/8960 - 255s - loss: 0.0617 - val_loss: 0.0633\n",
      "Epoch 5/1000\n",
      "8960/8960 - 258s - loss: 0.0599 - val_loss: 0.0617\n",
      "Epoch 6/1000\n",
      "8960/8960 - 252s - loss: 0.0591 - val_loss: 0.0617\n",
      "Epoch 7/1000\n",
      "8960/8960 - 254s - loss: 0.0566 - val_loss: 0.0618\n",
      "Epoch 8/1000\n",
      "8960/8960 - 278s - loss: 0.0549 - val_loss: 0.0595\n",
      "Epoch 9/1000\n",
      "8960/8960 - 272s - loss: 0.0526 - val_loss: 0.0600\n",
      "Epoch 10/1000\n",
      "8960/8960 - 262s - loss: 0.0513 - val_loss: 0.0667\n",
      "Epoch 11/1000\n",
      "8960/8960 - 261s - loss: 0.0492 - val_loss: 0.0593\n",
      "Epoch 12/1000\n",
      "8960/8960 - 258s - loss: 0.0468 - val_loss: 0.0582\n",
      "Epoch 13/1000\n",
      "8960/8960 - 259s - loss: 0.0444 - val_loss: 0.0610\n",
      "Epoch 14/1000\n",
      "8960/8960 - 246s - loss: 0.0435 - val_loss: 0.0668\n",
      "Epoch 15/1000\n",
      "8960/8960 - 248s - loss: 0.0409 - val_loss: 0.0611\n",
      "Epoch 16/1000\n",
      "8960/8960 - 270s - loss: 0.0384 - val_loss: 0.0756\n",
      "Epoch 17/1000\n",
      "8960/8960 - 275s - loss: 0.0359 - val_loss: 0.0644\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "batch size 1\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_2 (Masking)          (None, 47, 305)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 47, 256)           444416    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 47, 1)             257       \n",
      "=================================================================\n",
      "Total params: 444,673\n",
      "Trainable params: 444,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "8960/8960 - 274s - loss: 0.0664 - val_loss: 0.0656\n",
      "Epoch 2/1000\n",
      "8960/8960 - 259s - loss: 0.0638 - val_loss: 0.0647\n",
      "Epoch 3/1000\n",
      "8960/8960 - 258s - loss: 0.0627 - val_loss: 0.0640\n",
      "Epoch 4/1000\n",
      "8960/8960 - 260s - loss: 0.0622 - val_loss: 0.0652\n",
      "Epoch 5/1000\n",
      "8960/8960 - 267s - loss: 0.0613 - val_loss: 0.0653\n",
      "Epoch 6/1000\n",
      "8960/8960 - 261s - loss: 0.0604 - val_loss: 0.0627\n",
      "Epoch 7/1000\n",
      "8960/8960 - 272s - loss: 0.0588 - val_loss: 0.0643\n",
      "Epoch 8/1000\n",
      "8960/8960 - 256s - loss: 0.0567 - val_loss: 0.0603\n",
      "Epoch 9/1000\n",
      "8960/8960 - 299s - loss: 0.0555 - val_loss: 0.0587\n",
      "Epoch 10/1000\n",
      "8960/8960 - 307s - loss: 0.0527 - val_loss: 0.0614\n",
      "Epoch 11/1000\n",
      "8960/8960 - 300s - loss: 0.0512 - val_loss: 0.0568\n",
      "Epoch 12/1000\n",
      "8960/8960 - 292s - loss: 0.0498 - val_loss: 0.0578\n",
      "Epoch 13/1000\n",
      "8960/8960 - 305s - loss: 0.0479 - val_loss: 0.0570\n",
      "Epoch 14/1000\n",
      "8960/8960 - 264s - loss: 0.0459 - val_loss: 0.0624\n",
      "Epoch 15/1000\n",
      "8960/8960 - 245s - loss: 0.0440 - val_loss: 0.0699\n",
      "Epoch 16/1000\n",
      "8960/8960 - 242s - loss: 0.0423 - val_loss: 0.0624\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "batch size 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "normalized_compl = normalize(compl_measures_all, axis=2, order=2)\n",
    "normalied_validation = normalize(val_compl_measures, axis=2, order=2)\n",
    "eval_scores_compl = get_evaluation(normalized_compl, normalied_validation, padded_val_x, padded_labels_style_change,\n",
    "                                   scores)\n",
    "\n",
    "#----------------- embeddings\n",
    "padded_embeddings, padded_val_x_embeddings, padded_val_y_embeddings = pad_embeddings(embedding_all_docs,\n",
    "                                                                                     val_embedding_all_docs,\n",
    "                                                                                     val_labels,\n",
    "                                                                                     target)\n",
    "\n",
    "normalized_embeddings = normalize(padded_embeddings, axis=2, order=2)\n",
    "normalized_val_emb = normalize(padded_val_x_embeddings, axis=2, order=2)\n",
    "eval_scores_embeddings = get_evaluation(normalized_embeddings, normalized_val_emb, padded_val_y_embeddings,\n",
    "                                        padded_labels_style_change, scores)\n",
    "\n",
    "#----------------- combined complexity feats & embeddings\n",
    "combined_x = np.concatenate((np.array(normalized_embeddings), np.array(normalized_compl)), axis=2)\n",
    "combined_val = np.concatenate((np.array(normalized_val_emb), np.array(normalied_validation)), axis=2)\n",
    "combined_scores = get_evaluation(combined_x, combined_val, padded_val_y, padded_labels_style_change, scores)\n",
    "\n",
    "\n",
    "#----------------- baselines\n",
    "majority_baseline_scores, random_baseline_acc = baselines(padded_labels_style_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results complexity measures precision, recall, f1, accuracy: [0.9968423609424338, 0.8169331829341119, 0.8979651374808548, 0.9734232522796352]\n",
      "results embeddings precision, recall, f1, accuracy: [0.9469678568536961, 0.11289030452198252, 0.2017316913311946, 0.12078267477203647]\n",
      "results combined precision, recall, f1, accuracy: [0.9414622297789653, 0.11246953224745618, 0.20093486206032538, 0.12155205167173253]\n",
      "majority baseline accuracy: 0.8798442249240122\n",
      "random baseline accuracy: 0.6177336626139818\n"
     ]
    }
   ],
   "source": [
    "#----------------- print results\n",
    "print(\"results complexity measures precision, recall, f1, accuracy: \" + str(eval_scores_compl))\n",
    "print(\"results embeddings precision, recall, f1, accuracy: \" + str(eval_scores_embeddings))\n",
    "print(\"results combined precision, recall, f1, accuracy: \" + str(combined_scores))\n",
    "print(\"majority baseline accuracy: \" + str(majority_baseline_scores))\n",
    "print(\"random baseline accuracy: \" + str(random_baseline_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(x_train, x_test), (y_train, y_test) = imdb.load_data(num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "style-change-detection",
   "language": "python",
   "name": "style-change-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "be4254f328ae1375cca28a8f1f3d4506579f39c71d95f5fb35b954f5819eacea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}